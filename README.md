# SPARTANS-HACKX - INTEGRITY AI

This project aims to analyze a given piece of code or text and determine whether it is likely to be generated by an AI language model or written by a human. It leverages a combination of traditional natural language processing (NLP) techniques, deep learning models, and hybrid approaches to provide accurate and insightful results.

## Overview

The project utilizes a hybrid approach to code analysis, combining multiple methods such as Abstract Syntax Tree (AST) similarity, TF-IDF vectorization, and deep learning with transformers. This comprehensive analysis helps capture both the structural and semantic nuances of the input code.

### Features
- *Code Classification*: Uses a pre-trained transformer model (facebook/bart-large-mnli) to classify whether the code is AI-generated or human-written.
- *Multiple Similarity Metrics*: Computes both AST-based structural similarity and TF-IDF-based semantic similarity.
- *Code Complexity Analysis*: Analyzes code complexity by calculating metrics such as token count, average token length, and number of functions and classes.
- *User Interface*: Provides a simple and interactive web interface using Streamlit.

## Models and Research Papers Implemented

1. **Transformer Model (facebook/bart-large-mnli)**
   - A pre-trained transformer model from the BART family, fine-tuned on the Multi-Genre Natural Language Inference (MNLI) dataset, is used for text classification. This model helps differentiate nuanced patterns in code effectively.
   - *Research Paper*: ["CodeBERT: A Pre-Trained Model for Programming and Natural Languages"](https://ar5iv.labs.arxiv.org/html/2002.08155) [Feng, Zhang, et al., Findings of EMNLP 2020].
     - This paper discusses a pre-trained model, CodeBERT, which is designed for natural language and programming language understanding, similar to the transformer model approach used in this project.

2. *Abstract Syntax Tree (AST) Analysis*
   - The AST method parses the input code into a tree structure representing its syntax. Structural similarity between different code samples is measured using difflib to compare their AST representations.
   - *Relevant Research*: [Zhenyi Li, Shaohua Wang, Lin Shi, "Exploring Neural Models for Code Clone Detection," ICSE 2017].
     - This paper discusses AST-based methods for code clone detection, aligning with this projectâ€™s use of AST similarity for code classification.

3. *TF-IDF and Cosine Similarity*
   - Uses Term Frequency-Inverse Document Frequency (TF-IDF) vectorization and cosine similarity to measure the semantic similarity between code samples.
   - *Relevant Research*: [Ziyuan Wang, Shiqi Xu, Jifeng Xuan, et al., "A Novel Neural Source Code Representation Based on Abstract Syntax Tree," Neural Networks, 2019].
     - The paper explores methods for code representation, similar to the TF-IDF technique used in this project.

4. *Deep Learning for Source Code Modeling*
   - The project integrates multiple deep learning approaches for code analysis, which aligns with the methodologies discussed in [Zemin Liu, Mark Harman, Yue Jia, Federica Sarro, "Deep Learning for Source Code Modeling and Generation," ACM Computing Surveys, 2020].

5. *Semantic Program Embeddings with Graph Neural Networks*
   - Combines different forms of code analysis, mirroring the approach in [Miltiadis Allamanis, Marc Brockschmidt, Mahmoud Khademi, "Learning Semantic Program Embeddings with Graph Neural Networks," ICLR, 2018].

## File Description

- **app.py**: The main script that contains all functions and logic for the AI vs Human Code Detection tool. It includes:
  - preprocess_code(): Removes comments and normalizes whitespace in the code.
  - compute_ast_similarity(): Computes structural similarity using AST representations.
  - compute_tfidf_similarity(): Calculates semantic similarity using TF-IDF and cosine similarity.
  - calculate_code_metrics(): Analyzes basic code metrics like token count and average token length.
  - check_code_complexity(): Checks for complexity indicators such as the number of lines, functions, and classes.
  - is_generated_code(): Main function to classify whether the input code is AI-generated or human-written.
  - main(): The main function to run the Streamlit-based web application.

## How to Run the File

### Prerequisites

Make sure you have the following libraries installed:

```bash
pip install nltk transformers scikit-learn streamlit matplotlib
import nltk
nltk.download('punkt')
streamlit run app.py
        OR
streamlit run text.py
